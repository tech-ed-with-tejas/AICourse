{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['OPENAI_API_KEY'] = os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ['GROQ_API_KEY'] = os.getenv(\"GROQ_API_KEY\")\n",
    "os.environ['LANGCHAIN_API_KEY'] = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ['LANGCHAIN_PROJECT'] = os.getenv(\"LANGCHAIN_PROJECT\")\n",
    "os.environ['LANGCHAIN_TRACING_V2'] = \"true\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm=ChatOpenAI(model='o1-mini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=<openai.resources.chat.completions.completions.Completions object at 0x10e15ff20> async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x10e624560> root_client=<openai.OpenAI object at 0x10dc93080> root_async_client=<openai.AsyncOpenAI object at 0x10e5845f0> model_name='o1-mini' temperature=1.0 model_kwargs={} openai_api_key=SecretStr('**********')\n"
     ]
    }
   ],
   "source": [
    "print(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result = llm.invoke(\"WHat is ai \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='\\n<think>\\nOkay, I need to explain what AI is. Let\\'s start with the basics. AI stands for Artificial Intelligence. But what does that really mean? Maybe I should break it down. Artificial means made by humans, and intelligence refers to the ability to learn, understand, and make decisions. So AI is like a machine or a computer program that can perform tasks that typically require human intelligence.\\n\\nWait, but how do they do that? Probably through algorithms and data. I remember reading that AI systems can learn from data, right? Like machine learning, which is a subset of AI. Maybe I should mention that. There\\'s also deep learning, which uses neural networks. But maybe I don\\'t need to get too technical here.\\n\\nApplications are important too. People encounter AI every day without realizing it. Think of Siri, Alexa, recommendation systems on Netflix or Amazon. These are all examples of AI in action. Self-driving cars are another big example, using computer vision and complex algorithms to navigate.\\n\\nI should also touch on the types of AI. There\\'s narrow or weak AI, which is what we have now—systems designed for specific tasks. Then there\\'s general or strong AI, which is theoretical and can perform any intellectual task a human can. But we\\'re not there yet, right? Maybe clarify that distinction.\\n\\nEthics and challenges are crucial. Issues like bias in AI, privacy concerns, job displacement, and the need for regulation. It\\'s important to mention that AI isn\\'t just about technology; it has societal implications.\\n\\nI should also define the difference between AI, machine learning, and deep learning to avoid confusion. AI is the broader field, machine learning is a subset focused on learning from data, and deep learning is a subset of ML using neural networks.\\n\\nWait, the user wrote \"Hwat is AI?\"—they probably meant \"What is AI?\" Maybe a typo. I\\'ll proceed as if it\\'s a typo.\\n\\nLet me structure this. Start with a definition, then talk about how it works (learning from data, algorithms), types of AI, applications, and then the broader implications. Keep it simple but comprehensive. Make sure to use examples so it\\'s relatable.\\n\\nHmm, maybe start with a simple sentence: \"AI refers to the simulation of human intelligence in machines that are programmed to think like humans and mimic their actions.\" Then elaborate on the components like learning, reasoning, problem-solving.\\n\\nAlso, mention that AI can process vast amounts of data quickly, which humans can\\'t. That\\'s a key advantage. But also note limitations, like requiring large datasets, energy consumption, and the need for human oversight.\\n\\nWait, the user might be a beginner, so avoid jargon as much as possible. Use everyday examples. Maybe mention chatbots, facial recognition, spam filters as AI applications.\\n\\nOh, and the history? Maybe not necessary unless it\\'s too brief. Since the question is \"what is AI,\" focus on the present and basic understanding.\\n\\nPutting this all together in a coherent way without getting too technical. Make sure to cover the key points: definition, how it works, types, examples, and societal impact.\\n</think>\\n\\n**Artificial Intelligence (AI)** is a branch of computer science that aims to create machines or systems capable of performing tasks that typically require human intelligence. These tasks include learning, problem-solving, decision-making, perception (e.g., recognizing images or speech), and even creativity. AI systems mimic human cognitive functions through algorithms and data, enabling them to perform or assist in complex activities.\\n\\n### Key Components of AI:\\n1. **Learning**: AI systems analyze data to identify patterns, improve performance over time, and adapt to new information (e.g., a recommendation algorithm learning user preferences).\\n2. **Reasoning**: AI can make decisions or draw conclusions based on given data, rules, or logic (e.g., a chess program calculating moves).\\n3. **Problem-Solving**: AI tackles challenges by exploring possible solutions (e.g., route-planning in GPS navigation).\\n4. **Perception**: AI processes sensory inputs like images, sounds, or text (e.g., facial recognition software).\\n\\n### Types of AI:\\n- **Narrow (Weak) AI**: Designed for specific tasks. This is the most common form today. Examples include:\\n  - Virtual assistants (Siri, Alexa)\\n  - Spam filters\\n  - Self-driving cars (focused on navigation)\\n  - Chatbots\\n- **General (Strong) AI**: Hypothetical systems that can understand, learn, and apply knowledge across *any* intellectual task, like a human. This remains theoretical and doesn’t yet exist.\\n\\n### How AI Works:\\n- **Machine Learning (ML)**: A subset of AI where systems learn from data without explicit programming. For example, ML algorithms predict weather patterns by analyzing historical data.\\n- **Deep Learning**: A specialized ML technique using neural networks (inspired by the human brain) to process complex data. Used in applications like image recognition or language translation.\\n- **Natural Language Processing (NLP)**: Enables AI to understand and generate human language (e.g., chatbots, voice assistants).\\n\\n### Real-World Applications:\\n- **Healthcare**: Diagnosing diseases using medical imaging.\\n- **Finance**: Fraud detection, algorithmic trading.\\n- **Entertainment**: Personalized movie/ song recommendations (Netflix, Spotify).\\n- **Manufacturing**: Robotics for automated assembly lines.\\n- **Transportation**: Self-driving cars (Tesla, Waymo).\\n\\n### Challenges and Considerations:\\n- **Ethical Concerns**: Bias in data can lead to unfair outcomes (e.g., facial recognition errors in marginalized groups).\\n- **Privacy**: Data collection for AI raises concerns about personal information misuse.\\n- **Job Impact**: Automation may displace certain roles but also create new opportunities.\\n- **Societal Dependence**: Over-reliance on AI without human oversight can lead to errors (e.g., autonomous vehicle accidents).\\n\\n### Misconceptions:\\n- AI is not a single \"thinking\" entity but a collection of tools and algorithms.\\n- It doesn’t \"think\" like humans but excels at processing vast data and identifying patterns faster than humans.\\n\\nIn summary, AI is a transformative technology that empowers machines to perform intelligent tasks, revolutionizing industries, but it also raises important ethical and societal questions. Its future development hinges on balancing innovation with responsible use.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 1289, 'prompt_tokens': 15, 'total_tokens': 1304, 'completion_time': 3.144967084, 'prompt_time': 0.002889588, 'queue_time': 0.245591752, 'total_time': 3.147856672}, 'model_name': 'qwen-qwq-32b', 'system_fingerprint': 'fp_512a3da6bb', 'finish_reason': 'stop', 'logprobs': None}, id='run--48b78441-8616-4797-b25c-97f67af35f7c-0', usage_metadata={'input_tokens': 15, 'output_tokens': 1289, 'total_tokens': 1304})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model = ChatGroq(model=\"qwen-qwq-32b\")\n",
    "# model.invoke(\"Hwat is AI?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are an expert AI Engineer provide an answer based on the question'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\"You are an expert AI Engineer provide an answer based on the question\"),\n",
    "    (\"user\",\"{input}\")\n",
    "])\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatGroq(model=\"gemma2-9b-it\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are an expert AI Engineer provide an answer based on the question'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])\n",
       "| ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x114910140>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x11446e270>, model_name='gemma2-9b-it', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Artificial intelligence (AI) is the ability of a computer or machine to mimic human intelligence. This includes tasks like learning from data, recognizing patterns, making decisions, and understanding natural language. \\n\\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 42, 'prompt_tokens': 39, 'total_tokens': 81, 'completion_time': 0.076363636, 'prompt_time': 0.002359735, 'queue_time': 0.244593366, 'total_time': 0.078723371}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--f97695ea-0f07-4c33-8314-56dd62580af3-0', usage_metadata={'input_tokens': 39, 'output_tokens': 42, 'total_tokens': 81})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"input\",\"what is ai,please xplain in 50 words\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "## output praser \n",
    "from langchain_core.output_parsers import StrOutputParser,XMLOutputParser\n",
    "output_parser = XMLOutputParser()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The output should be formatted as a XML file.\\n1. Output should conform to the tags below.\\n2. If tags are not given, make them on your own.\\n3. Remember to always open and close all the tags.\\n\\nAs an example, for the tags [\"foo\", \"bar\", \"baz\"]:\\n1. String \"<foo>\\n   <bar>\\n      <baz></baz>\\n   </bar>\\n</foo>\" is a well-formatted instance of the schema.\\n2. String \"<foo>\\n   <bar>\\n   </foo>\" is a badly-formatted instance.\\n3. String \"<foo>\\n   <tag>\\n   </tag>\\n</foo>\" is a badly-formatted instance.\\n\\nHere are the output tags:\\n```\\nNone\\n```'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['query'], input_types={}, partial_variables={'format_instruction': 'The output should be formatted as a XML file.\\n1. Output should conform to the tags below.\\n2. If tags are not given, make them on your own.\\n3. Remember to always open and close all the tags.\\n\\nAs an example, for the tags [\"foo\", \"bar\", \"baz\"]:\\n1. String \"<foo>\\n   <bar>\\n      <baz></baz>\\n   </bar>\\n</foo>\" is a well-formatted instance of the schema.\\n2. String \"<foo>\\n   <bar>\\n   </foo>\" is a badly-formatted instance.\\n3. String \"<foo>\\n   <tag>\\n   </tag>\\n</foo>\" is a badly-formatted instance.\\n\\nHere are the output tags:\\n```\\nNone\\n```'}, template='Answere the user query \\n {format_instruction}\\n {query}\\n')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Answere the user query \\n {format_instruction}\\n {query}\\n\",\n",
    "    input_variables =['query'],\n",
    "    partial_variables={\"format_instruction\":output_parser.get_format_instructions()}\n",
    ")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt|model|output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chain.invoke({\"query\":\"what is lang smith in 50 words\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'response': [{'lang_smith_definition': 'Lang Smith is a large language model chatbot developed by Google DeepMind. It is trained on a massive dataset of text and code, enabling it to generate human-like text, translate languages, write different kinds of creative content, and answer your questions in an informative way.'}]}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class  Joke(BaseModel):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create simople assistance with pydantic any product thsi should give you 2 information product name and product details tentative price \n",
    "# USD price"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
